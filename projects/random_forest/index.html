<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Random Forest: News Article Classification | Patrick Richter</title> <meta name="author" content="Patrick Richter"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="machine-learning, artficial-intelligence, deep-learning, neural-networks"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://patrick-richter.github.io/projects/random_forest/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://patrick-richter.github.io/"><span class="font-weight-bold">Patrick</span> Richter</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Machine Learning Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Random Forest: News Article Classification</h1> <p class="post-description"></p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/3-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/3-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/3-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/3.jpg" width="auto" height="auto" title="News"> </picture> </figure> </div> </div> <p><br><br></p> <h3 id="dataset"><strong>Dataset</strong></h3> <p>Today, we will have a look at the <strong>AG’s News Topic Classification Dataset</strong>. The dataset includes <strong>title and description</strong> of news articles for <strong>120,000 training samples</strong> and <strong>7,600 test samples</strong>. Each of those is classified into one of the categories <strong>“World”</strong>, <strong>“Sports”</strong>, <strong>“Business”</strong>, or <strong>“Sci/Tech”</strong> (see <a href="https://github.com/mhjabreel/CharCnn_Keras/tree/master/data/ag_news_csv" target="_blank" rel="noopener noreferrer">here</a> for more information). Here you can see a random sample of the dataset:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Class: "Sci/Tech"
Title: "E-mail scam targets police chief",
Description: "Wiltshire Police warns about "phishing" after its fraud squad chief was targeted."
</code></pre></div></div> <p>We will implement a <strong>Random Forest classifier</strong> to learn this problem and hopefully achieve a good result on the test dataset. Before we get started, download and save the training data <a href="https://patrick-richter.github.io/assets/csv/train.csv">here</a> and the test data <a href="https://patrick-richter.github.io/assets/csv/test.csv">here</a> (make sure that you set the format to <code class="language-plaintext highlighter-rouge">Page Source</code>). <br><br></p> <h3 id="prerequirements"><strong>Prerequirements</strong></h3> <p>The project is written in <strong>Python</strong> and, before starting, make sure to install and import the following <strong>libraries</strong>.</p> <script src="https://gist.github.com/patrick-richter/99ac21582db0a17a0c517b972aad5b85.js"></script> <p><br><br></p> <h3 id="data-preprocessing"><strong>Data Preprocessing</strong></h3> <p>To be able to preprocess the data, the <strong>csv file</strong> is first of all <strong>read with pandas</strong> and transformed into a numpy array.</p> <script src="https://gist.github.com/patrick-richter/3d7f631daf32e7bde0de6cdfbc535995.js"></script> <p>The next step is to <strong>remove all stop words</strong> (words such as “the”, “I”, or “he” that occur so frequently that they are deemed irrelevant for the classification), <strong>digits</strong>, and <strong>punctuation</strong>. By using a pre-existing stop word list from the nltk library, the undesirable words can be easily discarded.</p> <script src="https://gist.github.com/patrick-richter/d8c164e531a5a04e6a44ea6e03289b95.js"></script> <p>Following that, the remaining words are stemmed, i.e., they are reduced to their base word or stem so that similar words are being represented by the same stem word. For example, ‘leaking’ and ‘leaks’ would both be converted to ‘leak’ and would therefore be seen as the same word in the upcoming steps. Due to better performance, the <strong>Porter Stemmer</strong>, which is slightly less aggressive than the alternative Snowball Stemmer, was implemented.</p> <script src="https://gist.github.com/patrick-richter/5f01be94de49aff396ae156e9e84e387.js"></script> <p>Finally, to make our data processable for the Random Forest classifier, we need to vectorise the text. There are several ways how to represent text in a vector. One of the most commonly used approaches that is also used here, is to count the occurrence of words. This <strong>count vectoriser</strong> approach returns a vector that counts how often each of the words in the vocabulary (all different words in the training data) occur for each sample.</p> <p>The problem we are facing here is that there are just <strong>too many different words</strong> in the training data (&gt;20,000) which would make it incredibly computational expensive. Therefore, the <code class="language-plaintext highlighter-rouge">max_features</code> parameter is here <strong>limited to 4,000</strong>, i.e., only the 4,000 most frequently occurring words are considered.</p> <script src="https://gist.github.com/patrick-richter/cfecf2c99c43520dff84d45b794b2982.js"></script> <p><br><br></p> <h3 id="random-forest-classifier"><strong>Random Forest Classifier</strong></h3> <p>Before we go into Random Forests themselves, it is important to understand how <strong>decision trees</strong> work. As you can see in the basic example bellow, decision trees always split in a way that the resulting subsamples are as dissimilar as possible. In other words, the tree decides to <strong>split the feature where it can gain the most information</strong>.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/14-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/14-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/14-1400.webp"></source> <img class="img-fluid" src="/assets/img/14.jpg" width="auto" height="auto" title="Decision tree"> </picture> </figure> </div> </div> <div class="caption"> Simple decision tree (source: <a href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" target="_blank" rel="noopener noreferrer">Towards Data Science</a>) </div> <p>A <strong>Random Forest</strong> is an <strong>ensemble of multiple decision trees</strong>, combining their predictions the wisdom of many to provide a more robust prediction (see figure below). To ensure that the trees are as uncorrelated as possible, Random Forest modifies the decision trees in two ways to add more randomness. <strong>Bagging</strong>, the first method, refers to the process that each tree is trained with a random subset of samples, instead of the whole dataset. <strong>Feature Randomness</strong> introduces randomness by only letting the decision trees pick from a subset of features at each point. Due to the highly uncorrelated trees and the prediction by committee, Random Forests are far more accurate than decision trees alone in their prediction.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/15-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/15-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/15-1400.webp"></source> <img class="img-fluid" src="/assets/img/15.jpg" width="auto" height="auto" title="Random Forest"> </picture> </figure> </div> </div> <div class="caption"> Random Forest (source: <a href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" target="_blank" rel="noopener noreferrer">Towards Data Science</a>) </div> <p><br><br></p> <h3 id="implementation"><strong>Implementation</strong></h3> <p>For this project, we will not implement the <strong>Random Forest classifier</strong> from scratch, but instead use the already implemented function from <code class="language-plaintext highlighter-rouge">scikit-learn</code>. If you are interested in checking out how to code the algorithm from scratch, check <a href="https://tonyalgo.com/machinelearning/randomforest" target="_blank" rel="noopener noreferrer">here</a>.</p> <p>The Random Forest classifier has two really important <strong>hyperparameters</strong>. <code class="language-plaintext highlighter-rouge">max_depth</code> determines how many nodes each decision tree can maximally have. From playing around with the hyperparameter, I achieved the best results with 2,000 (half of the vocabulary). The second import hyperparameter is <code class="language-plaintext highlighter-rouge">n_estimators</code>, the number of decision trees in the Random Forest. Generally, the more trees you have, the better the results will be. However, as you can see in the figure bellow, the test accuracy only improves slightly after 50 trees. In my code, I choose quite a high number of trees (300), but this will also take you more than 30 minutes to train.</p> <script src="https://gist.github.com/patrick-richter/cb7e3035227c9d02e9fc35e2afd8214f.js"></script> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/17-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/17-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/17-1400.webp"></source> <img class="img-fluid" src="/assets/img/17.jpg" width="auto" height="auto" title="Number of trees"> </picture> </figure> </div> </div> <p><br><br></p> <h3 id="results"><strong>Results</strong></h3> <p>By comparing the predictions with the real labels, we obtain the <strong>training and test accuracy</strong>:</p> <script src="https://gist.github.com/patrick-richter/981eaa67dfdba061b41c637ead27ebab.js"></script> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training accuracy: 99.95 %
Test accuracy: 89.11 %
</code></pre></div></div> <p>The achieved <strong>test accuracy of almost 90 %</strong> is quite impressive, especially considering that the Random Forest classifier is a comparatively simple algorithm in contrast to the Deep Neural Networks that would otherwise be used for such tasks. Moreover, by using count vectoriser as the vector representation, any context in the sentences is lost. If we had used a CNN for example, we could have implemented better representations such as Word Embedding. The current benchmark (they used a CNN) by <a href="https://papers.nips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf" target="_blank" rel="noopener noreferrer">Zhang et al. (2015)</a> for this dataset is 92 %.</p> <p>When looking at the <strong>confusion matrix</strong>, we can see that most of the prediction errors originate from mixing up the “Business” and “Sci/Tech” categories. “Sports”, as you would expect, is quite distinguishable and has the highest prediction accuracy with 97.2 %.</p> <script src="https://gist.github.com/patrick-richter/8615eb731b829098957ed27f49a7641b.js"></script> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/16-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/16-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/16-1400.webp"></source> <img class="img-fluid" src="/assets/img/16.jpg" width="auto" height="auto" title="Confustion matrix"> </picture> </figure> </div> </div> <div class="caption"> Confusion Matrix </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2022 Patrick Richter. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>