<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>CNN: Age Estimation and Gender Classification | Patrick Richter</title> <meta name="author" content="Patrick Richter"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="machine-learning, artficial-intelligence, deep-learning, neural-networks"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://patrick-richter.github.io/projects/cnn_face/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://patrick-richter.github.io/"><span class="font-weight-bold">Patrick</span> Richter</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Machine Learning Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">CNN: Age Estimation and Gender Classification</h1> <p class="post-description"></p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/30-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/30-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/30-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/30.jpg" width="auto" height="auto" title="Faces"> </picture> </figure> </div> </div> <p>One of the most important applications of Deep Learning is <strong>Computer Vision</strong>. Today, we will take a deeper dive into this topic and deploy a <strong>Convolutional Neural Network (CNN)</strong> to predict the age and the gender of faces from the <strong>UTKFace dataset</strong>. <br><br></p> <h3 id="dataset"><strong>Dataset</strong></h3> <p>The <strong>UTKFace dataset</strong> is a large-scale face dataset with an <strong>age span from 0 to 116 years old</strong> with a resolution of 128x128. However, to avoid long training durations, we will only use a <strong>subset of 5,000 images</strong>. You can download the dataset by clicking this <a href="https://patrick-richter.github.io/assets/zip/train_test.zip">Link</a> (full dataset can be found on <a href="https://www.kaggle.com/datasets/jangedoo/utkface-new" target="_blank" rel="noopener noreferrer">Kaggle</a>).</p> <p>The project is written in <strong>Python</strong> and, before starting, make sure to install and import the following <strong>libraries</strong>.</p> <script src="https://gist.github.com/patrick-richter/c31f5464e7cfae8f723d758591e4766d.js"></script> <p>To give you brief idea of how the data looks like, we will first <strong>visualise a couple of images</strong>. The labels regarding age and gender are hidden in the file name. For instance, the person with the file path <code class="language-plaintext highlighter-rouge">train_test/28_1_0_20170117180708809.jpg.chip.jpg</code> is 28 years old and is female (1 = female, 0 = male).</p> <script src="https://gist.github.com/patrick-richter/0f2dfb96c162191dc4c3b5ab40f2ed8b.js"></script> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/31-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/31-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/31-1400.webp"></source> <img class="img-fluid" src="/assets/img/31.jpg" width="auto" height="auto" title="Visualisation"> </picture> </figure> </div> </div> <div class="caption"> Visualisation of 20 faces </div> <p><br><br></p> <h3 id="data-preprocessing"><strong>Data Preprocessing</strong></h3> <p>Before we can start with preprocessing, the data needs to be stored in a pandas <code class="language-plaintext highlighter-rouge">DataFrame</code>. Then we can split the data into <strong>training and test data</strong>, with 20 % being used for testing purposes.</p> <script src="https://gist.github.com/patrick-richter/99b7a7ccd9da4ef629594623d9b96cc8.js"></script> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                                              filename   age  gender
0     train_test/86_1_0_20170120225751953.jpg.chip.jpg  86.0       1
1     train_test/26_1_0_20170116171048641.jpg.chip.jpg  26.0       1
2     train_test/52_0_1_20170117161018159.jpg.chip.jpg  52.0       0
3     train_test/16_0_0_20170104003740977.jpg.chip.jpg  16.0       0
4     train_test/27_0_3_20170119210058457.jpg.chip.jpg  27.0       0
...                                                ...   ...     ...
4995  train_test/86_1_2_20170105174813405.jpg.chip.jpg  86.0       1
4996  train_test/28_0_2_20170107212142294.jpg.chip.jpg  28.0       0
4997   train_test/1_1_0_20170109194452834.jpg.chip.jpg   1.0       1
4998  train_test/54_0_0_20170109010040814.jpg.chip.jpg  54.0       0
4999  train_test/52_0_3_20170119200211340.jpg.chip.jpg  52.0       0

[5000 rows x 3 columns]
</code></pre></div></div> <p><strong>Data Augmentation</strong> is an enormously useful tool that is used in most Computer Vision projects. By applying certain variations such as rotation, zoom, or a horizontal flip to the images, it artificially creates new training data from already existing training data</p> <p>It is so popular mainly due to two big advantages. First, it helps you <strong>getting more training</strong> data without having to mine new data. Secondly, it is a key tool to <strong>prevent overfitting</strong>. The model can never fit perfectly on the training data because each epoch you will have slight variations of each image.</p> <p>The easiest way of implementing Data Augmentation is with the <code class="language-plaintext highlighter-rouge">ImageDataGenerator</code> from <code class="language-plaintext highlighter-rouge">tensorflow</code>. Here, we apply rotation, zoom, and a horizontal flip to our images. Moreover, the rgb value range is scaled to 0 and 1.</p> <script src="https://gist.github.com/patrick-richter/139d7e751e09ed73c299f2c379c952a3.js"></script> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found 4000 validated image filenames.
Found 1000 validated image filenames.
</code></pre></div></div> <p><br><br></p> <h3 id="cnn-model-construction"><strong>CNN Model Construction</strong></h3> <p>As we are facing a <strong>muti-label problem</strong>, we need to construct a CNN model that outputs two different values. <code class="language-plaintext highlighter-rouge">keras</code> offers a way to split the model in two at any point of the Neural Network.</p> <p>Here, two of the three convolutional layers (including padding) are shared between the two branches. After the second convolutional layer, the age and the gender prediction <strong>split into two branches</strong>. Each of the branches include one more convolutional layer, one dense layer, and one output layer. As you can see below, dropout is also employed in each of the branches and in the shared-learning part.</p> <script src="https://gist.github.com/patrick-richter/138cd717b5c78177db74175152a015d8.js"></script> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/33-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/33-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/33-1400.webp"></source> <img class="img-fluid" src="/assets/img/33.jpg" width="auto" height="auto" title="Model architecture"> </picture> </figure> </div> </div> <div class="caption"> Model architecture </div> <p><br><br></p> <h3 id="model-training"><strong>Model Training</strong></h3> <p>The following step, obviously, is to <strong>train the model</strong>. Since the total loss is the sum of the age and the gender loss, we need to make sure that the values of the two loss functions are balanced. Therefore, we weigh the <code class="language-plaintext highlighter-rouge">binary_crossentropy</code> loss of the gender classification 500 times higher than the <code class="language-plaintext highlighter-rouge">mse</code> of the age estimation. The model is trained for 60 epochs.</p> <script src="https://gist.github.com/patrick-richter/603f720753c5e045a8b626d11480f5c3.js"></script> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/60
200/200 [==============================] - 15s 73ms/step - loss: 862.1603 - dense_age_loss: 521.0098 - dense_gender_loss: 0.6823 - dense_age_mae: 17.5374 - dense_gender_accuracy: 0.6021 - val_loss: 689.9260 - val_dense_age_loss: 393.1925 - val_dense_gender_loss: 0.5935 - val_dense_age_mae: 14.5779 - val_dense_gender_accuracy: 0.6960
Epoch 2/60
200/200 [==============================] - 14s 72ms/step - loss: 664.3820 - dense_age_loss: 365.3248 - dense_gender_loss: 0.5981 - dense_age_mae: 14.6565 - dense_gender_accuracy: 0.6846 - val_loss: 592.0073 - val_dense_age_loss: 328.2217 - val_dense_gender_loss: 0.5276 - val_dense_age_mae: 13.6442 - val_dense_gender_accuracy: 0.7430

...

Epoch 59/60
200/200 [==============================] - 15s 73ms/step - loss: 275.9303 - dense_age_loss: 138.7035 - dense_gender_loss: 0.2745 - dense_age_mae: 8.8752 - dense_gender_accuracy: 0.8787 - val_loss: 294.9626 - val_dense_age_loss: 132.8631 - val_dense_gender_loss: 0.3242 - val_dense_age_mae: 8.2970 - val_dense_gender_accuracy: 0.8750
Epoch 60/60
200/200 [==============================] - 15s 74ms/step - loss: 266.4663 - dense_age_loss: 129.6572 - dense_gender_loss: 0.2736 - dense_age_mae: 8.6207 - dense_gender_accuracy: 0.8847 - val_loss: 278.6100 - val_dense_age_loss: 122.3719 - val_dense_gender_loss: 0.3125 - val_dense_age_mae: 8.1059 - val_dense_gender_accuracy: 0.8770
</code></pre></div></div> <p><br><br></p> <h3 id="results"><strong>Results</strong></h3> <p>On the test data, the model achieves an <strong>8.11 MAE on age estimation</strong> and an <strong>87.70 % accuracy on gender classification</strong>. This is a good result, considering the small dataset and the fact that two different variables are predicted in one model.</p> <p>When we plot the <strong>training curves</strong>, we can see that due to dropout and data augmentation there is <strong>no over- or underfitting</strong> present.</p> <script src="https://gist.github.com/patrick-richter/3b25d563450db7b877f50099a7d1c7b7.js"></script> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/34-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/34-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/34-1400.webp"></source> <img class="img-fluid" src="/assets/img/34.jpg" width="auto" height="auto" title="Training performance"> </picture> </figure> </div> </div> <div class="caption"> Training performance </div> <p>Finally, to give you an idea of how the predictions look like with images present, I sampled 20 images and printed out the prediction with the actual label in brackets. Especially the age estimation would be quite hard even for humans.</p> <script src="https://gist.github.com/patrick-richter/dc92047f522be9562f6f2e8bdfc791e0.js"></script> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/32-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/32-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/32-1400.webp"></source> <img class="img-fluid" src="/assets/img/32.jpg" width="auto" height="auto" title="Predictions"> </picture> </figure> </div> </div> <div class="caption"> 20 Faces with prediction and actual age and gender in brackets </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2022 Patrick Richter. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>